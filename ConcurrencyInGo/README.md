# Concurrency in Go

- [Concurrency in Go](#concurrency-in-go)
  - [동시성이 어려운 이유](#동시성이-어려운-이유)
  - [복잡성 속의 단순함](#복잡성-속의-단순함)
  - [고루틴](#고루틴)
  - [sync 패키지](#sync-패키지)
    - [WaitGroup](#waitgroup)
    - [Mutex와 RWMutex](#mutex와-rwmutex)
    - [Cond](#cond)
    - [Pool](#pool)
  - [채널](#채널)

<br>

## 동시성이 어려운 이유
- **레이스 컨디션**<br>
대부분 이 문제는 하나의 동시 작업이 어떤 변수를 읽으려고 시도하는 동안 또 다른 동시 작업이 특정할 수 없는 시점에 동일 변수에 값을 쓰려고 하는 데이터 레이스인 것으로 밝혀졌다.<br><br>
대부분의 데이터 레이스는 개발자가 문제를 순차적으로 생각하기 때문에 일어난다. 개발자들은 어떤 한 줄의 코드가 다른 코드보다 먼저 나타나기 때문에 먼저 실행될 것이라고 가정한다.<br><br>
레이스 컨디션은 동시성 버그 중 가장 은밀한 유형 중 하나다. 코드가 운영 환경에 투입된 후에도 수년 동안 드러나지 않을 수 있기 때문이다. 그러다가 코드가 실행되는 환경의 변화로 인해 갑작스럽게 버그가 발생한다.

- **원자성**<br>
무언가가 원자적이거나 원자적인 속성을 가진다면, 이는 동작하는 컨텍스트 내에서 나누어지거나 중단되지 않는다는 것을 의미한다. 이때 가장 중요한 것은 컨텍스트라는 용어이다. 어떤 컨텍스트에서는 원자적인 것이 다른 컨텍스트에서는 아닐 수 있다.<br><br>
`i++` 는 간단한 예제이지만 원자성의 개념을 쉽게 보여준다. 이 예시가 원자적으로 보일 수도 있지만, 간단한 분석을 통해 몇 가지 연산으로 구성돼 있음을 알 수 있다.

    - i의 값을 가져온다.
    - i의 값을 증가시킨다.
    - i의 값을 저장한다.<br><br>

    이런 각 연산은 원자적이지만, 세 연산의 조합은 컨텍스트에 따라 원자적이지 않을 수 있다. 즉, 원자적 연산을 조합한다고해서 반드시 더 큰 원자적 연산이 생성되는 것은 아니라는 점이다. 연산을 원자적으로 만드는 것은 사용자가 어떤 컨텍스트에서 원자성을 얻고자 하는지에 달려 있다.<br><br>
    원자 성이 중요한 이유는 무언가가 원자적이라면 암묵적으로 동시에 실행되는 컨텍스트들 내에서는 안전하다는 것을 의미하기때문이다.

- **메모리 접근 동기화**<br>
프로그램에서 공유 리소스에 독점적으로 접근해야 하는 영역을 칭하는 이름이 있는데 이를 임계 영역이라고 한다. 이 임계 영역을 발견하면 메모리에 대한 접근을 동기화하기 위한 (Mutex와 같은)포인트를 추가하라. 꽤 간단해보이는 방법이지만 이것이 데이터 레이스나 논리적인 정확성을 자동으로 해결하지는 못한다. 또한 이 방식이 유지 관리 및 성능 문제를 일으킬 수도 있다.

- **데드락**<br>
프로그램이 데드락 상태에 빠지면, 해당 프로그램에서 동시에 실행 중인 모든 프로세스는 자신이 아닌 다른 프로세스가 끝나기만을 기다린다. 데드락 상태가 되면 외부 개입이 없이는 결코 프로그램을 복구할 수 없다.<br><br>
데드락의 정의를 확실히 하기 위해 아래 예제를 살펴보자.

    ```go
    type value struct {
        mu sync.Mutex
        value int
    }

    var wg sync.WaitGroup
    printSum := func(v1, v2 *value) {
        defer wg.Done()
        v1.mu.Lock()
        defer v1.mu.Unlock()

        time.Sleep(2*time.Second)
        v2.mu.Lock()
        defer v2.mu.Unlock()

        fmt.Printf("sum=%v\n", v1.value + v2.value)
    }

    var a, b value
    wg.Add(2)
    go printSum(&a, &b)
    go printSum(&b, &a)
    wg.Wait()
    ```
    첫번째 printSum 호출은 a를 잠근 다음 b를 잠그려고 시도하지만, 그 사이에 두 번째 printSum 호출이 b를 잠그고 a를 잠그려고 시도했다. 두 고루틴은 서로를 무한히 기다린다.

- **라이브락**<br>

- **기아상태**<br>

- **동시실행 안정성 판단**<br>

<br>

## 복잡성 속의 단순함
예를 들어, 웹 서버를 작성하는 데 수락된 모든 연결이 다른 모든 연결과 동시에 처리되도록 하고 싶다고 가정해보자. 일부 언어에서는 웹 서버가 연결 수락을 시작하기 전에 일반적으로 스레드 풀이라고 하는 스레드 컬렉션을 만든 다음, 들어오는 연결을 스레드로 매핑해야한다. 그런 다음, 생성한 각 스레드 내에서 해당 스레드의 모든 연결을 돌면서 그들이 모두 CPU 시간을 할당 받을 수 있도록 해야 한다. 게다가 다른 연결과 공평하게 공유할 수 있도록 연결을 처리하는 논리를 중간에 멈출 수 있도록 작성해야한다.<br><br>
이와는 달리 Go에서는 함수를 작성한 다음, 이를 호출할 때 앞에 go 키워드를 추가하면 된다. 그러면 런타임이 앞서 논의한 모든 것을 자동으로 처리한다!

---

---

<br>

## 고루틴
고루틴은 다른 코드와 함께 동시에 실행되는 함수이다. 그렇다고 고루틴이 반드시 병렬로 실행되는 것은 아니다! 실제로 모든 Go 프로그램에는 적어도 하나의 고루틴이 있다. 프로세스가 시작될 때 자동으로 생성되고 시작되는 main 고루틴이 바로 그것이다.

```go
func main() {
    go sayHello()
    // 다른 작업들을 계속한다
}

func sayHello() {
    fmt.Println("hello")
}
```

```go
func main() {
    go func() {
        fmt.Println("hello")
    }()
    // 다른 작업들을 계속한다
}
```

```go
func main() {
    sayHello := func() {
        fmt.Println("hello")
    }

    go sayHello()
    // 다른 작업들을 계속한다
}
```

얼마나 멋진가! 함수 하나와 키워드 하나만 사용해 동시에 실행되는 논리 블록을 만들 수 있다!<br><br>

Go는 `fork-join 모델`이라는 동시성 모델을 따른다. fork라는 단어는 프로그램의 어느 지점에서든지 실행의 자식 분기를 만들어 부모와 동시에 실행할 수 있다는 사실을 나타낸다. 그리고 join이라는 단어는 미래의 어느 시점에서 이렇게 동시에 실행된 분기가 다시 합쳐진다는 사실을 나타낸다. 자식 분기가 다시 부모 분기와 합쳐지는 지점을 합류 지점이라고 한다.

```go
func main() {
    sayHello := func() {
        fmt.Println("hello")
    }

    go sayHello()
    // 다른 작업들을 계속한다
}
```
이 예제에는 한 가지 문제가 있다. 작성된 대로 sayHello 함수가 실행될지 아닐지 전혀 알 수 없다는 점이다. 이 고루틴은 Go의 런타임을 통해 실행되도록 생성 및 스케줄링되지만, 실제로는 main 고루틴이 종료되기 전에 실행될 기회를 얻지 못할 수도 있다. 고루틴을 생성한 후에 time.Sleep을 둘 수도 있지만, 이는 실제로 합류 지점을 만드는 것이 아니라 단지 레이스 컨디션을 일으킬 뿐이라는 것을 기억하자. 종료되기 전에 실행될 확률이 늘어나기는 하지만 실행을 보장할 수는 없다. 합류 지점은 프로그램의 정확성을 보증하고 레이스 컨디션을 제거하는 요소이다.

## sync 패키지
### WaitGroup
WaitGroup은 동시에 수행된 연산의 결과를 신경 쓰지 않거나, 결과를 수집할 다른 방법이 있는 경우 동시에 수행될 연산 집합을 기다릴 때 유용하다.

```go
var wg sync.WaitGroup

wg.Add(1)
go func() {
    defer wg.Done()
    fmt.Println("1st goroutine sleeping...")
    time.Sleep(1)
}()

wg.Add(1)
fo func() {
    defer wg.Done()
    fmt.Println("2nd goroutine sleeping...")
    time.Sleep(2)
}()

wg.Wait()
fmt.Println("All goroutine complete.")
```

Add 호출은 전달된 정수만큼 카운터를 증가시키고, Done은 카운터를 1만큼 감소시킨다. Wait를 호출하면 카운터가 0이 될때까지 대기한다. Add에 대한 호출을 고루틴의 외부에서 수행하는 것이 추적에 도움이 된다는 점에 주목하자. 이전에 언급했듯이 언제 고루틴이 스케줄링될지 확신할 수 없다는 점을 기억해야한다. 고루틴 중 하나가 시작되기도 전에 Wait 호출에 도달할 수도 있다. Add에 대한 호출이 고루틴의 클로저 내부에서 이루어지면 Add에 대한 호출이 일어나지 않을 수도 있다. 따라서 Wait를 호출하더라도 전혀 대기하지 않고 바로 리턴될 수도 있었다.

<br>

### Mutex와 RWMutex
Mutex는 상호 배제(mutual exclusion)의 약자로, 프로그램의 임계 영역을 보호하는 방법이다. 임계 영역이란 공유 리소스에 독점적으로 접근해야 하는 프로그램 영역을 말하는데, Mutex는 이러한 공유 리소스에 대해 동시에 실행해도 안전한 방식의 배타적 접근을 나타내는 방법을 제공한다. Go의 방식을 빌려 말하자면, 채널은 통신을 통해 메모리를 공유하는 반면, Mutex는 개발자가 메모리에 대한 접근을 동기화하기 위해 따라야 하는 규칙을 만들어 메모리를 공유한다.

```go
var count int
var lock sync.Mutex

increment := func () {
    lock.Lock()
    defer lock.Unlock()
    count++
    fmt.Printf("Incrementing: %d\n", count)
}
```
항상 defer 구문 내에서 Unlock을 호출한다는 점을 알 수 있을 것이다. 이것은 Mutex에서 매우 흔하게 사용되는 관용구로, 패닉이 발생하는 경우를 포함해 모든 경우에 Unlock이 확실하게 호출되는 것을 보장한다. 그렇게 하지 않으면 프로그램이 데드락에 빠질 수 있다.

sync.RWMutex는 Mutex와 동일하게 메모리에 대한 접근을 보호한다. 그러나 RWMutex는 조금 더 메모리를 제어할 수 있게 해준다. 에를 들어 읽기 잠금을 요청할 수 있지만, 다른 프로세스가 쓰기 잠금을 가지고 있지 않은 경우에만 접근 권한이 부여된다. 즉, 아무도 쓰기 잠금을 보유하고 있지 않다면 몇 개의 프로세스든 읽기 잠금을 보유할 수 있다.

<br>

### Cond
두 개 이상의 고루틴 사이에서 어떤 사실이 발생했다는 사실외에는 아무런 정보를 전달하지 않는 임의의 신호를 이벤트라고 하는데 고루틴이 이벤트를 받을 때까지 슬립하고 자신의 상태를 확인할 수 있는 효율적인 방법이 있다면 좋을 것이다. 이것이 정확히 Cond 타입이 해주는 일이다.

```go
c := sync.NewCond(&sync.Mutex{})
queue := make([]interface{}, 0, 10) // Empty interfaces match to any type (like generic)

removeFromQueue := func(delay time.Duration) {
    time.Sleep(delay)
    c.L.Lock()
    queue = queue[1:]
    fmt.Println("Removed from queue")
    c.L.Unlock()
    c.Signal() // Broadcast() method
}

for i := 0; i < 10; i++ {
    c.L.Lock()
    for len(queue) == 2 {
        c.Wait()
    }

    fmt.Println("Adding to queue")
    queue = append(queue, struct{}{})
    go removeFromQueue(1*time.Second)
    c.L.Unlock()
}
```

Wait에 대한 호출은 단지 멈춰서 대기하는 것이 아니라, 현재 고루틴을 일시 중단해 다른 고루틴이 OS 스레드에서 실행될 수 있도록 한다. Wait를 호출하면 몇몇 다른 작업도 이루어진다. 진입할 때 Cond 변수의 Locker에서 Unlock이 호출되고, Wait가 종료되면 Cond 변수의 Locker에서 Lock이 호출된다. 조건이 발생할 때까지 기다리면서 계속 이 lock을 가지고 있는 것처럼 보이지만 실제로는 그렇지 않다.<br><br>

이 예제에서는 Signal이라는 새로운 메서드도 등장한다. 내부적으로 런타임은 신호가 오기를 기다리는 고루틴들의 FIFO(First In First Out) 목록을 유지한다. Signal 메서드는 가장 오래 기다린 고루틴을 찾아서 알려주는 반면, Brodcast는 기다리고 있는 모든 고루틴들에게 신호를 보낸다. (즉, Brodcast는 여러 개의 고루틴들과 한 번에 통신할 수 있는 방법을 제공함)

### Pool
Pool은 동시에 실행해도 안전한 객체 풀 패턴의 구현이다. 높은 수준에서의 풀 패턴은 고정된 개수만큼의 사용할 것들, 즉 풀을 생성해두고 활용할 수 있게하는 방법이다. Go에는 가비지 컬렉터가 있으므로 인스턴스화된 객체는 자동으로 정리됨에도 불구하고 왜 쓰는 만큼 객체를 인스턴스화하지 않고 풀을 사용하는가?<br><br>

```go
```

Pool은 가능한 한 빨리 실행해야 하는 작업을 위해 사전에 할당된 객체의 캐시를 준비해 두는 경우에 유용하다. 이 경우 사전 로딩을 통해 다른 객체에 대한 참조를 가져오는데 걸리는 시간을 아껴서 고객의 시간을 보호한다. 가능한 한 신속하게 요청에 응답하려고 하는, 높은 처리 성능의 네트워크 서버를 작성하는 경우에 이는 매우 일반적이다.

**Pool 사용 여부에 대한 성능 비교 예제**
```go
```

<br>

## 채널
채널을 사용할 때는 값을 chan 변수에 전달한 다음, 프로그램의 다른 곳에서 채널을 읽는다. 프로그램의 서로 다른 두 부분은 서로에 대해 알 필요가 없으며, 채널이 존재하는 메모리상의 동일한 위치에 대한 참조만 알면 된다.

```go
// 선언
var dataStream chan interface{} // 비어있는 interface이므로 어떠한 종류의 데이터도 위치시킬 수 있는 채널임

// 인스턴스화
dataStream = make(chan interface{})
```

`화살표가 가리키는 쪽의 변수로 데이터가 흐른다`는 점을 떠올리면 이해하기 쉽다.
* 송신 `dataStream <-`
* 수신 `<- dataStream`

```go
stringStream := make(chan string)
go func() {
    stringStream <- "Hello channels!"
}()
fmt.Println(<-stringStream)
```

3장의 앞부분에서 고루틴이 스케줄링됐다고 해서 프로세스가 종료되기 전에 고루틴이 실행될 것이라는 보장은 없다는 사실을 강조했다. 그러나 앞의 예제는 실행되지 않고 생략되는 코드 없이 완전하고 정확하다. 어째서 main 고루틴이 끝나기 전에 익명 고루틴이 완료될 수 있는 것일까? 보통 Go의 채널은 멈춰서 기다리고 있다고 하는데, 이로 인해 위 예제는 잘 동작한다. 즉, 가득 찬 채널에 쓰려고 하는 고루틴은 채널이 비워질 때까지 기다리고, 비어 있는 채널에서 읽으려는 고루틴은 적어도 하나의 항목이 있을 때까지 기다린다.